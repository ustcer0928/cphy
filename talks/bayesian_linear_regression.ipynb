{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble and Imports\n",
    "\n",
    "* This notebook is modified notebooks originally developed in [Pankaj Mehta's ML for physics course](http://physics.bu.edu/~pankajm/PY580.html), although I've added some modification based on [Volodymyr Kuleshov's applied ML course](https://github.com/kuleshov/cornell-cs5785-2022-applied-ml)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preamble / required packages\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(0)\n",
    "\n",
    "# Import local plotting functions and in-notebook display functions\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "# Comment this out to activate warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian linear regression\n",
    "\n",
    "In this notebook, we will explore Bayesian linear regression. We will start with a simple example and then move on to a more complex example. We will also compare the Bayesian approach with the frequentist approach.\n",
    "\n",
    "### Simple example\n",
    "\n",
    "Let's start with a simple example. We will generate some data from a linear model with Gaussian noise. We will then fit a linear model to the data using Bayesian linear regression. We will compare the results with the frequentist approach.\n",
    "\n",
    "First, let's import the necessary libraries.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "```\n",
    "\n",
    "We will generate the data from a linear model with Gaussian noise. The model is\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\epsilon\n",
    "$$\n",
    "\n",
    "where $\\beta_0$ and $\\beta_1$ are the parameters of the model and $\\epsilon$ is the Gaussian noise. We will generate the data using the following code.\n",
    "\n",
    "```python\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(123)\n",
    "n = 100\n",
    "x = np.random.randn(n)\n",
    "eps = np.random.randn(n)\n",
    "beta0 = 1\n",
    "beta1 = 2\n",
    "y = beta0 + beta1 * x + eps\n",
    "```\n",
    "\n",
    "Let's plot the data.\n",
    "\n",
    "```python\n",
    "plt.plot(x, y, 'o')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "```\n",
    "\n",
    "We will now fit a linear model to the data using Bayesian linear regression. We will use the `pymc3` library to do this. The model is\n",
    "\n",
    "$$\n",
    "y \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x, \\sigma^2)\n",
    "$$\n",
    "\n",
    "where $\\beta_0$, $\\beta_1$, and $\\sigma$ are the parameters of the model. We will use a uniform prior for $\\beta_0$ and $\\beta_1$ and a half-normal prior for $\\sigma$. We will use the following code to fit the model.\n",
    "\n",
    "```python\n",
    "with pm.Model() as model:\n",
    "    # Priors\n",
    "    beta0 = pm.Uniform('beta0', lower=-10, upper=10)\n",
    "    beta1 = pm.Uniform('beta1', lower=-10, upper=10)\n",
    "    sigma = pm.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    # Likelihood\n",
    "    y_pred = pm.Normal('y_pred', mu=beta0 + beta1 * x, sd=sigma, observed=y)\n",
    "    \n",
    "    # Inference\n",
    "    trace = pm.sample(1000, tune=1000, cores=2)\n",
    "```\n",
    "\n",
    "Let's plot the posterior distributions of the parameters.\n",
    "\n",
    "```python\n",
    "az.plot_trace(trace)\n",
    "```\n",
    "\n",
    "We can also plot the posterior predictive distribution of the model.\n",
    "\n",
    "```python\n",
    "az.plot_posterior_predictive_glm(trace, samples=100, label='posterior predictive regression lines')\n",
    "plt.plot(x, y, 'o', label='data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightGBM\n",
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cphy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e972983abb2b5c6293c34082f6ff1f6e60e8afbd2a068e0026ccecbb212fdb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
